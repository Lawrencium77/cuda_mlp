# Cuda MLP
Training an MLP on MNIST in raw CUDA.

## TODO

* Figure out why the MLP and SLP forward methods return the same result.
* Cross-entropy loss.
* Backprop.

### Later On

* Faster operations, e.g. tiled matmuls.
